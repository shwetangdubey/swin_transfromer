{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d373832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f12f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as T\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, sampler, random_split\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e52e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "#import torchvision image models\n",
    "from timm.loss import LabelSmoothingCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2461c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa10123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf8e1a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(data_dir):\n",
    "    all_data = datasets.ImageFolder(data_dir)\n",
    "    return all_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54a43914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(data_dir, batch_size, train = False):\n",
    "    if train:\n",
    "        transform = T.Compose([\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.RandomVerticalFlip(),\n",
    "            T.RandomApply(torch.nn.ModuleList([T.ColorJitter()]), p = 0.25),\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD),\n",
    "            #imagenet means\n",
    "            T.RandomErasing(p = 0.1, value = 'random')\n",
    "        ])\n",
    "        \n",
    "        train_data = datasets.ImageFolder(os.path.join(data_dir, 'train\\\\'), transform=transform)\n",
    "        train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, num_workers= 4)\n",
    "        return train_loader, len(train_data)\n",
    "    else:\n",
    "        transform = T.Compose([\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(timm.data.IMAGENET_DEFAULT_MEAN, timm.data.IMAGENET_DEFAULT_STD)\n",
    "            \n",
    "        ])\n",
    "        val_data = datasets.ImageFolder(os.path.join(data_dir, \"valid\\\\\"), transform = transform)\n",
    "        test_data = datasets.ImageFolder(os.path.join(data_dir, \"test\\\\\"), transform = transform)\n",
    "        val_loader = DataLoader(val_data, batch_size = batch_size , shuffle=True, num_workers=4)\n",
    "        test_loader = DataLoader(test_data, batch_size= batch_size, shuffle =True, num_workers = 4)\n",
    "        return val_loader, test_loader, len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ba9e25a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opendatasets in c:\\users\\shwet\\appdata\\roaming\\python\\python39\\site-packages (0.1.22)\n",
      "Requirement already satisfied: kaggle in c:\\users\\shwet\\appdata\\roaming\\python\\python39\\site-packages (from opendatasets) (1.5.13)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from opendatasets) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from opendatasets) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->opendatasets) (0.4.5)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.28.1)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2022.9.14)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.26.11)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: python-slugify in c:\\programdata\\anaconda3\\lib\\site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kaggle->opendatasets) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e410e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"C:\\F\\f_drive\\dataset\\archive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a6bcaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\F\\f_drive\\dataset\\archive\n"
     ]
    }
   ],
   "source": [
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "224ff13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\F\\f_drive\\dataset\\archive\\valid\\\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(dataset_path, 'valid\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8703b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_loader, train_data_len) = get_data_loaders(dataset_path, batch_size=128, train = True)\n",
    "(val_loader, test_loader, val_data_len, test_data_len) = get_data_loaders(dataset_path, batch_size =32 , train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12fd3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = get_classes(r'C:\\F\\f_drive\\dataset\\archive\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f2d015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d26b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'val': val_loader\n",
    "}\n",
    "dataset_sizes = {\n",
    "    'train': train_data_len,\n",
    "    'val' : val_data_len\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e8524b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 4 4\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(test_loader), len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "933bac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12639 500 500\n"
     ]
    }
   ],
   "source": [
    "print(train_data_len, test_data_len, val_data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c4d91c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\shwet/.cache\\torch\\hub\\SharanSMenon_swin-transformer-hub_main\n"
     ]
    }
   ],
   "source": [
    "HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\n",
    "MODEL_NAME = \"swin_tiny_patch4_window7_224\"\n",
    "#load from hub \n",
    "model = torch.hub.load(HUB_URL, MODEL_NAME, pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a352f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freez model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cc87dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (layers): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      dim=96, input_resolution=(56, 56), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=96, window_size=(7, 7), num_heads=3\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=96, input_resolution=(56, 56), num_heads=3, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=96, window_size=(7, 7), num_heads=3\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.009)\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(56, 56), dim=96\n",
      "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      dim=192, input_resolution=(28, 28), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=192, window_size=(7, 7), num_heads=6\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.018)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=192, input_resolution=(28, 28), num_heads=6, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=192, window_size=(7, 7), num_heads=6\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.027)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(28, 28), dim=192\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      dim=384, input_resolution=(14, 14), depth=6\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.036)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.045)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.055)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.064)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.073)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          dim=384, input_resolution=(14, 14), num_heads=12, window_size=7, shift_size=3, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=384, window_size=(7, 7), num_heads=12\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.082)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (downsample): PatchMerging(\n",
      "        input_resolution=(14, 14), dim=384\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      dim=768, input_resolution=(7, 7), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=768, window_size=(7, 7), num_heads=24\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.091)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=768, input_resolution=(7, 7), num_heads=24, window_size=7, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=768, window_size=(7, 7), num_heads=24\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.100)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
      "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bccba537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 Sequential(\n",
      "  (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=512, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "n_input = model.head.in_features\n",
    "model.head = nn.Sequential(\n",
    "        nn.Linear(n_input, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, len(classes))\n",
    ")\n",
    "print(n_input, model.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "055cb669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36091370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Linear(in_features=512, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "print(model.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab642c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = LabelSmoothingCrossEntropy()\n",
    "criterion = criterion.to(device)\n",
    "optimizer = optim.AdamW(model.head.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c12ec4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size= 3, gamma= 0.97)\n",
    "#lr scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079d2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8d218b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs = 10):\n",
    "    since = time.time()\n",
    "    best_model_wt = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/ {num_epochs - 1}')\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:    # Training and validation phase per epoch\n",
    "            if phase == 'train':\n",
    "                model.train()   #model to training phase\n",
    "            else:\n",
    "                model.eval()  #model to evaluation phase\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):  #no autograd makes validation step faster\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step() #step at end of epoch\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print(\"{} Loss : {:.4f} Acc : {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wt = copy.deepcopy(model.state_dict())   #keep the best vlidation accuracy model\n",
    "                \n",
    "        print()\n",
    "        \n",
    "    time_elapsed  = time.time() - since  \n",
    "    print(\"training complete in {:.0f}m {:.0f}s\".format(time_elapsed //60, time_elapsed % 60))\n",
    "    print(\"Best val acc : {:.4f}\".format(best_acc))\n",
    "        \n",
    "        \n",
    "    model.load_state_dict(best_model_wt)\n",
    "    return model\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e666c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/ 7\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [01:14<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss : 1.6534 Acc : 0.7865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss : 1.4415 Acc : 0.8760\n",
      "\n",
      "Epoch 1/ 7\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [01:16<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss : 1.4427 Acc : 0.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss : 1.3111 Acc : 0.9100\n",
      "\n",
      "Epoch 2/ 7\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [01:16<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss : 1.3356 Acc : 0.8859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss : 1.2505 Acc : 0.9020\n",
      "\n",
      "Epoch 3/ 7\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [01:16<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss : 1.2816 Acc : 0.8996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss : 1.2071 Acc : 0.9180\n",
      "\n",
      "Epoch 4/ 7\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [01:16<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss : 1.2377 Acc : 0.9115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss : 1.1801 Acc : 0.9240\n",
      "\n",
      "Epoch 5/ 7\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [01:16<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss : 1.2056 Acc : 0.9236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss : 1.1601 Acc : 0.9300\n",
      "\n",
      "Epoch 6/ 7\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [01:16<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss : 1.1797 Acc : 0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss : 1.1549 Acc : 0.9420\n",
      "\n",
      "Epoch 7/ 7\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 99/99 [01:17<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss : 1.1603 Acc : 0.9325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss : 1.1344 Acc : 0.9300\n",
      "\n",
      "training complete in 10m 57s\n",
      "Best val acc : 0.9420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a80110b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0463\n",
      "Test Accuracy of ADONIS: 100 % ( 4/ 4)\n",
      "Test Accuracy of AFRICAN GIANT SWALLOWTAIL: 100 % ( 5/ 5)\n",
      "Test Accuracy of AMERICAN SNOOT: 80 % ( 4/ 5)\n",
      "Test Accuracy of AN 88: 100 % ( 5/ 5)\n",
      "Test Accuracy of APPOLLO: 100 % ( 5/ 5)\n",
      "Test Accuracy of ARCIGERA FLOWER MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of ATALA: 100 % ( 5/ 5)\n",
      "Test Accuracy of ATLAS MOTH: 80 % ( 4/ 5)\n",
      "Test Accuracy of BANDED ORANGE HELICONIAN: 100 % ( 4/ 4)\n",
      "Test Accuracy of BANDED PEACOCK: 100 % ( 5/ 5)\n",
      "Test Accuracy of BANDED TIGER MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of BECKERS WHITE: 100 % ( 5/ 5)\n",
      "Test Accuracy of BIRD CHERRY ERMINE MOTH: 75 % ( 3/ 4)\n",
      "Test Accuracy of BLACK HAIRSTREAK: 100 % ( 5/ 5)\n",
      "Test Accuracy of BLUE MORPHO: 80 % ( 4/ 5)\n",
      "Test Accuracy of BLUE SPOTTED CROW: 100 % ( 5/ 5)\n",
      "Test Accuracy of BROOKES BIRDWING: 100 % ( 5/ 5)\n",
      "Test Accuracy of BROWN ARGUS: 100 % ( 4/ 4)\n",
      "Test Accuracy of BROWN SIPROETA: 100 % ( 4/ 4)\n",
      "Test Accuracy of CABBAGE WHITE: 100 % ( 5/ 5)\n",
      "Test Accuracy of CAIRNS BIRDWING: 100 % ( 5/ 5)\n",
      "Test Accuracy of CHALK HILL BLUE: 80 % ( 4/ 5)\n",
      "Test Accuracy of CHECQUERED SKIPPER: 100 % ( 5/ 5)\n",
      "Test Accuracy of CHESTNUT: 100 % ( 5/ 5)\n",
      "Test Accuracy of CINNABAR MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of CLEARWING MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of CLEOPATRA: 60 % ( 3/ 5)\n",
      "Test Accuracy of CLODIUS PARNASSIAN: 100 % ( 5/ 5)\n",
      "Test Accuracy of CLOUDED SULPHUR: 50 % ( 2/ 4)\n",
      "Test Accuracy of COMET MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of COMMON BANDED AWL: 100 % ( 5/ 5)\n",
      "Test Accuracy of COMMON WOOD-NYMPH: 100 % ( 5/ 5)\n",
      "Test Accuracy of COPPER TAIL: 100 % ( 5/ 5)\n",
      "Test Accuracy of CRECENT: 80 % ( 4/ 5)\n",
      "Test Accuracy of CRIMSON PATCH: 100 % ( 5/ 5)\n",
      "Test Accuracy of DANAID EGGFLY: 80 % ( 4/ 5)\n",
      "Test Accuracy of EASTERN COMA: 100 % ( 4/ 4)\n",
      "Test Accuracy of EASTERN DAPPLE WHITE: 80 % ( 4/ 5)\n",
      "Test Accuracy of EASTERN PINE ELFIN: 100 % ( 5/ 5)\n",
      "Test Accuracy of ELBOWED PIERROT: 100 % ( 5/ 5)\n",
      "Test Accuracy of EMPEROR GUM MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of GARDEN TIGER MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of GIANT LEOPARD MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of GLITTERING SAPPHIRE: 100 % ( 5/ 5)\n",
      "Test Accuracy of GOLD BANDED: 100 % ( 5/ 5)\n",
      "Test Accuracy of GREAT EGGFLY: 80 % ( 4/ 5)\n",
      "Test Accuracy of GREAT JAY: 100 % ( 3/ 3)\n",
      "Test Accuracy of GREEN CELLED CATTLEHEART: 100 % ( 5/ 5)\n",
      "Test Accuracy of GREEN HAIRSTREAK: 100 % ( 5/ 5)\n",
      "Test Accuracy of GREY HAIRSTREAK: 100 % ( 4/ 4)\n",
      "Test Accuracy of HERCULES MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of HUMMING BIRD HAWK MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of INDRA SWALLOW: 100 % ( 5/ 5)\n",
      "Test Accuracy of IO MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of Iphiclus sister: 100 % ( 5/ 5)\n",
      "Test Accuracy of JULIA: 100 % ( 5/ 5)\n",
      "Test Accuracy of LARGE MARBLE: 75 % ( 3/ 4)\n",
      "Test Accuracy of LUNA MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of MADAGASCAN SUNSET MOTH: 100 % ( 4/ 4)\n",
      "Test Accuracy of MALACHITE: 100 % ( 5/ 5)\n",
      "Test Accuracy of MANGROVE SKIPPER: 100 % ( 5/ 5)\n",
      "Test Accuracy of MESTRA: 80 % ( 4/ 5)\n",
      "Test Accuracy of METALMARK: 100 % ( 5/ 5)\n",
      "Test Accuracy of MILBERTS TORTOISESHELL: 80 % ( 4/ 5)\n",
      "Test Accuracy of MONARCH: 100 % ( 5/ 5)\n",
      "Test Accuracy of MOURNING CLOAK: 100 % ( 4/ 4)\n",
      "Test Accuracy of OLEANDER HAWK MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of ORANGE OAKLEAF: 75 % ( 3/ 4)\n",
      "Test Accuracy of ORANGE TIP: 100 % ( 5/ 5)\n",
      "Test Accuracy of ORCHARD SWALLOW: 100 % ( 4/ 4)\n",
      "Test Accuracy of PAINTED LADY: 100 % ( 5/ 5)\n",
      "Test Accuracy of PAPER KITE: 100 % ( 5/ 5)\n",
      "Test Accuracy of PEACOCK: 100 % ( 5/ 5)\n",
      "Test Accuracy of PINE WHITE: 100 % ( 5/ 5)\n",
      "Test Accuracy of PIPEVINE SWALLOW: 100 % ( 5/ 5)\n",
      "Test Accuracy of POLYPHEMUS MOTH: 100 % ( 3/ 3)\n",
      "Test Accuracy of POPINJAY: 100 % ( 5/ 5)\n",
      "Test Accuracy of PURPLE HAIRSTREAK: 40 % ( 2/ 5)\n",
      "Test Accuracy of PURPLISH COPPER: 40 % ( 2/ 5)\n",
      "Test Accuracy of QUESTION MARK: 80 % ( 4/ 5)\n",
      "Test Accuracy of RED ADMIRAL: 100 % ( 5/ 5)\n",
      "Test Accuracy of RED CRACKER: 100 % ( 5/ 5)\n",
      "Test Accuracy of RED POSTMAN: 100 % ( 5/ 5)\n",
      "Test Accuracy of RED SPOTTED PURPLE: 100 % ( 5/ 5)\n",
      "Test Accuracy of ROSY MAPLE MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of SCARCE SWALLOW: 100 % ( 5/ 5)\n",
      "Test Accuracy of SILVER SPOT SKIPPER: 100 % ( 5/ 5)\n",
      "Test Accuracy of SIXSPOT BURNET MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of SLEEPY ORANGE: 40 % ( 2/ 5)\n",
      "Test Accuracy of SOOTYWING: 100 % ( 5/ 5)\n",
      "Test Accuracy of SOUTHERN DOGFACE: 100 % ( 4/ 4)\n",
      "Test Accuracy of STRAITED QUEEN: 100 % ( 5/ 5)\n",
      "Test Accuracy of TROPICAL LEAFWING: 100 % ( 5/ 5)\n",
      "Test Accuracy of TWO BARRED FLASHER: 100 % ( 5/ 5)\n",
      "Test Accuracy of ULYSES: 100 % ( 4/ 4)\n",
      "Test Accuracy of VICEROY: 100 % ( 5/ 5)\n",
      "Test Accuracy of WHITE LINED SPHINX MOTH: 100 % ( 5/ 5)\n",
      "Test Accuracy of WOOD SATYR: 100 % ( 4/ 4)\n",
      "Test Accuracy of YELLOW SWALLOW TAIL: 80 % ( 4/ 5)\n",
      "Test Accuracy of ZEBRA LONG WING: 100 % ( 5/ 5)\n",
      "Test accuracy of 94% (452480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Lets run the dataset on the test loader and calculate accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0 for i in range(len(classes)))\n",
    "class_total = list(0 for i in range(len(classes)))\n",
    "model_ft.eval()\n",
    "\n",
    "for data, traget in tqdm(test_loader):\n",
    "    data, traget = data.to(device), traget.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model_ft(data)\n",
    "        loss = criterion(output, traget)\n",
    "        test_loss = loss.item() * data.size(0)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        correct_tensor = pred.eq(traget.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.cpu().numpy())\n",
    "        if len(traget) == 32:\n",
    "            for i in range(32):\n",
    "                label = traget.data[i]\n",
    "                class_correct[label] += correct[i].item()\n",
    "                class_total[label] += 1\n",
    "                \n",
    "test_loss = test_loss / test_data_len\n",
    "print('Test Loss: {:.4f}'.format(test_loss))\n",
    "for i in range(len(classes)):\n",
    "    if class_total[i] > 0:\n",
    "        print(\"Test Accuracy of %5s: %2d %% (%2d/%2d)\"%(classes[i], 100 * class_correct[i] / class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "        \n",
    "    else:\n",
    "        print(\"Test accuracy of %5s : NA\" % (classes[i]))\n",
    "        \n",
    "print(\"Test accuracy of %2d%% (%2d%2d)\" % (100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "28e694bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████▋                                    | 9/16 [00:02<00:01,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 15/16 [00:02<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  5.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for data, traget in tqdm(test_loader):\n",
    "    data, traget = data.to(device), traget.to(device)\n",
    "    print(len(traget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0d1d5225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shwet/.cache\\torch\\hub\\SharanSMenon_swin-transformer-hub_main\\swin.py:236: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert L == H * W, \"input feature has wrong size\"\n",
      "C:\\Users\\shwet/.cache\\torch\\hub\\SharanSMenon_swin-transformer-hub_main\\swin.py:59: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
      "C:\\Users\\shwet/.cache\\torch\\hub\\SharanSMenon_swin-transformer-hub_main\\swin.py:313: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert L == H * W, \"input feature has wrong size\"\n"
     ]
    }
   ],
   "source": [
    "example = torch.rand(1,3, 224,224)\n",
    "traced_script_module = torch.jit.trace(model.cpu(), example)\n",
    "traced_script_module.save(\"butterfly_swin_transformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "421497e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is OS\n",
      " Volume Serial Number is 4839-38DC\n",
      "\n",
      " Directory of C:\\Users\\shwet\n",
      "\n",
      "03-03-2023  00:19    <DIR>          .\n",
      "10-02-2023  02:39    <DIR>          ..\n",
      "02-03-2023  03:34    <DIR>          .cache\n",
      "14-02-2023  03:38    <DIR>          .conda\n",
      "27-01-2023  17:23               188 .gitconfig\n",
      "01-03-2023  18:44    <DIR>          .ipynb_checkpoints\n",
      "14-02-2023  02:03    <DIR>          .ipython\n",
      "14-02-2023  03:15    <DIR>          .jupyter\n",
      "28-02-2023  12:30    <DIR>          .keras\n",
      "16-02-2023  03:53    <DIR>          .matplotlib\n",
      "20-01-2023  23:42    <DIR>          .ms-ad\n",
      "24-01-2023  18:00    <DIR>          .RapidMiner\n",
      "18-01-2023  17:27    <DIR>          .virtualenvs\n",
      "18-01-2023  17:22    <DIR>          .vscode\n",
      "25-01-2023  15:20    <DIR>          ansel\n",
      "17-02-2023  20:32             5,154 bar_code_creater.ipynb\n",
      "03-03-2023  00:19       113,434,106 butterfly_swin_transformer.pt\n",
      "18-01-2023  17:23    <DIR>          code\n",
      "10-02-2023  02:42    <DIR>          Contacts\n",
      "10-02-2023  02:42    <DIR>          Desktop\n",
      "10-02-2023  02:42    <DIR>          Documents\n",
      "02-03-2023  03:43    <DIR>          Downloads\n",
      "10-02-2023  02:42    <DIR>          Favorites\n",
      "10-02-2023  02:42    <DIR>          Links\n",
      "10-02-2023  02:42    <DIR>          Music\n",
      "02-03-2023  18:45    <DIR>          OneDrive\n",
      "10-02-2023  02:42    <DIR>          Pictures\n",
      "10-02-2023  02:42    <DIR>          Saved Games\n",
      "10-02-2023  02:42    <DIR>          Searches\n",
      "17-02-2023  17:49            10,786 Sift_feature_extraction.ipynb\n",
      "16-02-2023  03:57    <DIR>          tensorflow_datasets\n",
      "14-02-2023  02:17             2,566 Untitled.ipynb\n",
      "14-02-2023  03:33           160,363 Untitled1.ipynb\n",
      "16-02-2023  04:01            22,093 Untitled2.ipynb\n",
      "16-02-2023  20:49               589 Untitled3.ipynb\n",
      "19-02-2023  21:45             6,887 Untitled4.ipynb\n",
      "01-03-2023  10:54            29,435 Untitled5.ipynb\n",
      "01-03-2023  11:21            50,904 Untitled6.ipynb\n",
      "01-03-2023  12:39            12,503 Untitled7.ipynb\n",
      "03-03-2023  00:19            53,117 Untitled8.ipynb\n",
      "18-02-2023  02:18             7,034 video_frames.ipynb\n",
      "01-03-2023  18:43    <DIR>          Videos\n",
      "              14 File(s)    113,795,725 bytes\n",
      "              28 Dir(s)  231,046,492,160 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea908ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
